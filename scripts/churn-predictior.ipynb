{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction using Neural Networks\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the process of building, training, and evaluating a neural network model for predicting customer churn. We use an augmented dataset for training and validation, and a separate test set for final evaluation.\n",
    "\n",
    "## Dataset\n",
    "- Training data: \"../data/augmented-training data.csv\"\n",
    "- Test data: \"../customer_churn_dataset-testing-master.csv\"\n",
    "\n",
    "## Key Steps\n",
    "1. Data Loading and Preprocessing\n",
    "   - Load training and test datasets\n",
    "   - Split training data into train and validation sets\n",
    "   - Scale features using StandardScaler\n",
    "\n",
    "2. Model Architecture\n",
    "   - Sequential model with Dense layers\n",
    "   - Batch Normalization and Dropout for regularization\n",
    "   - Binary classification with sigmoid activation\n",
    "\n",
    "3. Model Training\n",
    "   - Use Adam optimizer and binary crossentropy loss\n",
    "   - Train for 50 epochs with early stopping\n",
    "\n",
    "4. Model Evaluation\n",
    "   - Evaluate on separate test set\n",
    "   - Generate classification report and confusion matrix\n",
    "\n",
    "5. Visualizations\n",
    "   - Plot training and validation accuracy/loss curves\n",
    "\n",
    "## Requirements\n",
    "- Python 3.x\n",
    "- Libraries: pandas, numpy, sklearn, tensorflow, matplotlib, seaborn\n",
    "\n",
    "## Usage\n",
    "Run the cells in order to load data, build the model, train, and evaluate results. Adjust hyperparameters as needed for optimization.\n",
    "\n",
    "## Results\n",
    "The notebook will output:\n",
    "- Model accuracy and loss on test set\n",
    "- Classification report with precision, recall, and F1-score\n",
    "- Confusion matrix visualization\n",
    "- Training history plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess the data\n",
    "def load_and_preprocess_data(train_file, test_file):\n",
    "    \"\"\"\n",
    "    Load the CSV files and preprocess the data.\n",
    "    \"\"\"\n",
    "    # Load the CSV files\n",
    "    train_df = pd.read_csv(train_file)\n",
    "    test_df = pd.read_csv(test_file)\n",
    "    \n",
    "    # Separate features and target for training data\n",
    "    X_train = train_df.drop('Churn', axis=1)\n",
    "    y_train = train_df['Churn']\n",
    "    \n",
    "    # Separate features and target for test data\n",
    "    X_test = test_df.drop('Churn', axis=1)\n",
    "    y_test = test_df['Churn']\n",
    "    \n",
    "    # Split the training data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the neural network model\n",
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    Build and compile the neural network model.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the model\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=50, batch_size=32):\n",
    "    \"\"\"\n",
    "    Train the model and return the training history.\n",
    "    \"\"\"\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        verbose=1)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model and print the results.\n",
    "    \"\"\"\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test loss: {loss:.4f}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int).reshape(-1)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_classes))\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot the training and validation accuracy and loss.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = load_and_preprocess_data(\n",
    "        \"../data/augmented-training data.csv\",\n",
    "        \"../customer_churn_dataset-testing-master.csv\"\n",
    "    )\n",
    "\n",
    "# Build the model\n",
    "model = build_model(X_train.shape[1])\n",
    "\n",
    "# Train the model\n",
    "history = train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, X_test, y_test)\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
